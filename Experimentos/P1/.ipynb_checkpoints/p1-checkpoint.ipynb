{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento:\n",
    "\n",
    "Buscamos lograr contestar la pregunta: \n",
    "- ¿Es posible predecir la felicidad (positividad) de una canción en función de la popularidad (u otros parametros)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_excel('../Spotify.xlsx')\n",
    "df_spotify = pd.DataFrame(dataframe)\n",
    "\n",
    "#Ajustamos columnas para contraarrestar error de formato en archivo xlsx\n",
    "df_spotify['duration_ms'] = df_spotify['duration_ms']/10\n",
    "df_spotify['popularity'] = df_spotify['popularity']/10\n",
    "df_spotify['streams'] = df_spotify['streams']/10\n",
    "df_spotify['af_danceability'] = df_spotify['af_danceability']/1000\n",
    "df_spotify['af_energy'] = df_spotify['af_energy']/1000\n",
    "df_spotify['af_key'] = df_spotify['af_key']/10\n",
    "df_spotify['af_loudness'] = df_spotify['af_loudness']/1000\n",
    "df_spotify['af_speechiness'] = df_spotify['af_speechiness']/1000\n",
    "df_spotify['af_acousticness'] = df_spotify['af_acousticness']/1000\n",
    "df_spotify['af_instrumentalness'] = df_spotify['af_instrumentalness']/1000\n",
    "df_spotify['af_liveness'] = df_spotify['af_liveness']/1000\n",
    "df_spotify['af_valence'] = df_spotify['af_valence']/1000\n",
    "df_spotify['af_tempo'] = df_spotify['af_tempo']/1000\n",
    "df_spotify['af_time_signature'] = df_spotify['af_time_signature']/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciendo con solo popularidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util = df_spotify[[\"streams\", \"popularity\", \"af_valence\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_etiqueta(elemento):\n",
    "    if (elemento <= 0.25):\n",
    "        return \"Low\"\n",
    "    elif (elemento > 0.25) & (elemento <= 0.5):\n",
    "        return \"Medium-Low\"\n",
    "    elif (elemento > 0.5) & (elemento <= 0.75):\n",
    "        return \"Medium-High\"\n",
    "    else:\n",
    "        return \"High\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_etiquetado = df_util.copy()\n",
    "\n",
    "df_etiquetado[\"af_valence\"] = df_etiquetado[\"af_valence\"].apply(apply_etiqueta)\n",
    "X = df_etiquetado[[\"streams\", \"popularity\"]]\n",
    "y = df_etiquetado[\"af_valence\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.19      0.19      0.19     58190\n",
      "         Low       0.17      0.17      0.17     52533\n",
      " Medium-High       0.36      0.36      0.36    109647\n",
      "  Medium-Low       0.27      0.27      0.27     82345\n",
      "\n",
      "    accuracy                           0.27    302715\n",
      "   macro avg       0.25      0.25      0.25    302715\n",
      "weighted avg       0.27      0.27      0.27    302715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy = 'stratified')\n",
    "\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dummy_clf.predict(X_val)\n",
    "\n",
    "kn_acc = accuracy_score(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación de parámetros:\n",
      "{'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "tuned_parameters = {'n_neighbors': list(range(1, 16, 1))}\n",
    "\n",
    "score = 'f1_macro'\n",
    "\n",
    "cls = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(cls, param_grid = tuned_parameters, scoring = score, cv = 5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.25      0.25      0.25     58190\n",
      "         Low       0.22      0.22      0.22     52533\n",
      " Medium-High       0.40      0.40      0.40    109647\n",
      "  Medium-Low       0.33      0.33      0.33     82345\n",
      "\n",
      "    accuracy                           0.32    302715\n",
      "   macro avg       0.30      0.30      0.30    302715\n",
      "weighted avg       0.32      0.32      0.32    302715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kn_clf_1 = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "kn_clf_1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = kn_clf_1.predict(X_val)\n",
    "\n",
    "kn_acc = accuracy_score(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación de parámetros:\n",
      "{'criterion': 'gini', 'max_depth': 15}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "tuned_parameters = {'max_depth': list(range(1, 16, 1)), 'criterion': ['gini', 'entropy']}\n",
    "score = 'f1_macro'\n",
    "cls = DecisionTreeClassifier()\n",
    "\n",
    "clf = GridSearchCV(cls, param_grid = tuned_parameters, scoring = score, cv = 5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.47      0.37      0.41     58190\n",
      "         Low       0.49      0.20      0.29     52533\n",
      " Medium-High       0.49      0.65      0.56    109647\n",
      "  Medium-Low       0.47      0.50      0.49     82345\n",
      "\n",
      "    accuracy                           0.48    302715\n",
      "   macro avg       0.48      0.43      0.44    302715\n",
      "weighted avg       0.48      0.48      0.46    302715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree_clf = DecisionTreeClassifier(max_depth = 15, criterion = 'gini')\n",
    "\n",
    "dtree_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dtree_clf.predict(X_val)\n",
    "\n",
    "kn_acc = accuracy_score(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/Desarrollo/DCC/Codigo-DCC/Mineria-CC5205/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/diego/Desarrollo/DCC/Codigo-DCC/Mineria-CC5205/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.21      0.02      0.03     58190\n",
      "         Low       0.00      0.00      0.00     52533\n",
      " Medium-High       0.37      0.86      0.52    109647\n",
      "  Medium-Low       0.29      0.16      0.21     82345\n",
      "\n",
      "    accuracy                           0.36    302715\n",
      "   macro avg       0.22      0.26      0.19    302715\n",
      "weighted avg       0.26      0.36      0.25    302715\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/Desarrollo/DCC/Codigo-DCC/Mineria-CC5205/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb_clf.predict(X_val)\n",
    "\n",
    "kn_acc = accuracy_score(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "svm_clf = SVC()\n",
    "\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_clf.predict(X_val)\n",
    "\n",
    "kn_acc = accuracy_score(y_val, y_pred)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
