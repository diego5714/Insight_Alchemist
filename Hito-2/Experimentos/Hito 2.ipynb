{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 1:\n",
    "- ¿Es posible predecir la felicidad (positividad) de una canción en función de la popularidad (u otros parametros)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spotify = pd.read_excel('Spotify.xlsx')\n",
    "\n",
    "#Ajustamos columnas para contraarrestar error de formato en archivo xlsx\n",
    "df_spotify['duration_ms'] = df_spotify['duration_ms']/10\n",
    "df_spotify['popularity'] = df_spotify['popularity']/10\n",
    "df_spotify['streams'] = df_spotify['streams']/10\n",
    "df_spotify['af_danceability'] = df_spotify['af_danceability']/1000\n",
    "df_spotify['af_energy'] = df_spotify['af_energy']/1000\n",
    "df_spotify['af_key'] = df_spotify['af_key']/10\n",
    "df_spotify['af_loudness'] = df_spotify['af_loudness']/1000\n",
    "df_spotify['af_speechiness'] = df_spotify['af_speechiness']/1000\n",
    "df_spotify['af_acousticness'] = df_spotify['af_acousticness']/1000\n",
    "df_spotify['af_instrumentalness'] = df_spotify['af_instrumentalness']/1000\n",
    "df_spotify['af_liveness'] = df_spotify['af_liveness']/1000\n",
    "df_spotify['af_valence'] = df_spotify['af_valence']/1000\n",
    "df_spotify['af_tempo'] = df_spotify['af_tempo']/1000\n",
    "df_spotify['af_time_signature'] = df_spotify['af_time_signature']/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciendo con solo popularidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En una primera instancia, experimentaremos sólo usando los atributos \"streams\" y \"popularity\" para intentar predecir \"af_valence\" (El cual representa la positividad o felicidad). Esto es porque de todos lo atributos, son estos dos los que se asocian con la \"popularidad\" de una canción dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util_1 = df_spotify[[\"streams\", \"popularity\", \"af_valence\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>streams</th>\n",
       "      <th>popularity</th>\n",
       "      <th>af_valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28838.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218751.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193855.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>179042.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009045</th>\n",
       "      <td>11984.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009046</th>\n",
       "      <td>11904.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009047</th>\n",
       "      <td>11894.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009048</th>\n",
       "      <td>11751.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009049</th>\n",
       "      <td>11481.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009050 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          streams  popularity  af_valence\n",
       "0         28838.0        44.0       0.251\n",
       "1         22249.0         1.0       0.393\n",
       "2        218751.0        64.0       0.822\n",
       "3        193855.0        74.0       0.453\n",
       "4        179042.0        72.0       0.055\n",
       "...           ...         ...         ...\n",
       "1009045   11984.0        22.0       0.855\n",
       "1009046   11904.0        53.0       0.025\n",
       "1009047   11894.0        45.0       0.227\n",
       "1009048   11751.0         0.0       0.669\n",
       "1009049   11481.0        49.0       0.329\n",
       "\n",
       "[1009050 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función que nos permitirá convertir los valores numéricos reales del atributo \"af_valence\" en etiquetas de texto mediante intervalos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_etiqueta(elemento):\n",
    "    if (elemento <= 0.25):\n",
    "        return \"Low\"\n",
    "    elif (elemento > 0.25) & (elemento <= 0.5):\n",
    "        return \"Medium-Low\"\n",
    "    elif (elemento > 0.5) & (elemento <= 0.75):\n",
    "        return \"Medium-High\"\n",
    "    else:\n",
    "        return \"High\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a separar las etiquetas de los datos y a aplicar un scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_etiquetado_1 = df_util_1.copy()\n",
    "\n",
    "df_etiquetado_1[\"af_valence\"] = df_etiquetado_1[\"af_valence\"].apply(apply_etiqueta)\n",
    "X_1 = df_etiquetado_1.drop(columns = 'af_valence')\n",
    "y_1 = df_etiquetado_1[\"af_valence\"]\n",
    "\n",
    "X_scaled_1 = pd.DataFrame(StandardScaler().fit_transform(X_1), columns = X_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>streams</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.209665</td>\n",
       "      <td>-0.391136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.228652</td>\n",
       "      <td>-1.953110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.337597</td>\n",
       "      <td>0.335363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.265856</td>\n",
       "      <td>0.698613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.223170</td>\n",
       "      <td>0.625963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009045</th>\n",
       "      <td>-0.258232</td>\n",
       "      <td>-1.190286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009046</th>\n",
       "      <td>-0.258463</td>\n",
       "      <td>-0.064212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009047</th>\n",
       "      <td>-0.258492</td>\n",
       "      <td>-0.354812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009048</th>\n",
       "      <td>-0.258904</td>\n",
       "      <td>-1.989435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009049</th>\n",
       "      <td>-0.259682</td>\n",
       "      <td>-0.209512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009050 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          streams  popularity\n",
       "0       -0.209665   -0.391136\n",
       "1       -0.228652   -1.953110\n",
       "2        0.337597    0.335363\n",
       "3        0.265856    0.698613\n",
       "4        0.223170    0.625963\n",
       "...           ...         ...\n",
       "1009045 -0.258232   -1.190286\n",
       "1009046 -0.258463   -0.064212\n",
       "1009047 -0.258492   -0.354812\n",
       "1009048 -0.258904   -1.989435\n",
       "1009049 -0.259682   -0.209512\n",
       "\n",
       "[1009050 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos la separación del conjunto de datos de entrenamiento y el de validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_1, X_val_1, y_train_1, y_val_1 = train_test_split(X_scaled_1, y_1, test_size=0.3, random_state=0, stratify=y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder comparar los resultados obtenidos con otros clasificadores con un baseline conocido, ejecutamos una predicción con un dummy classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.19      0.19      0.19     58190\n",
      "         Low       0.18      0.18      0.18     52533\n",
      " Medium-High       0.36      0.36      0.36    109647\n",
      "  Medium-Low       0.27      0.27      0.27     82345\n",
      "\n",
      "    accuracy                           0.27    302715\n",
      "   macro avg       0.25      0.25      0.25    302715\n",
      "weighted avg       0.27      0.27      0.27    302715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy = 'stratified')\n",
    "\n",
    "dummy_clf.fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred_1 = dummy_clf.predict(X_val_1)\n",
    "\n",
    "kn_acc = accuracy_score(y_val_1, y_pred_1)\n",
    "print(classification_report(y_val_1, y_pred_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos haciendo una búsqueda para encontrar los parámetros mas idóneos con GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "tuned_parameters = {'n_neighbors': list(range(1, 16, 1)), 'weights': ['uniform', 'distance']}\n",
    "\n",
    "score = 'f1_macro'\n",
    "\n",
    "cls = KNeighborsClassifier(n_jobs = -1)\n",
    "\n",
    "clf = GridSearchCV(cls, param_grid = tuned_parameters, scoring = score, cv = 5)\n",
    "\n",
    "clf.fit(X_train_1, y_train_1)\n",
    "\n",
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.42      0.40      0.41     58190\n",
      "         Low       0.39      0.30      0.34     52533\n",
      " Medium-High       0.50      0.60      0.55    109647\n",
      "  Medium-Low       0.49      0.44      0.46     82345\n",
      "\n",
      "    accuracy                           0.47    302715\n",
      "   macro avg       0.45      0.44      0.44    302715\n",
      "weighted avg       0.46      0.47      0.46    302715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kn_clf_15 = KNeighborsClassifier(n_neighbors=15, weights = 'uniform', n_jobs = -1)\n",
    "\n",
    "kn_clf_15.fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred_1 = kn_clf_15.predict(X_val_1)\n",
    "\n",
    "kn_acc = accuracy_score(y_val_1, y_pred_1)\n",
    "print(classification_report(y_val_1, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados no son terribles, considerando que son bastante mejores que dummy, pero tampoco son buenos. En ningun caso logramos scores mayores a 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente optimizamos los parametros de entrada con GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación de parámetros:\n",
      "{'criterion': 'gini', 'max_depth': 15}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "tuned_parameters = {'max_depth': list(range(1, 16, 1)), 'criterion': ['gini', 'entropy']}\n",
    "score = 'f1_macro'\n",
    "cls = DecisionTreeClassifier()\n",
    "\n",
    "clf = GridSearchCV(cls, param_grid = tuned_parameters, scoring = score, cv = 5)\n",
    "\n",
    "clf.fit(X_train_1, y_train_1)\n",
    "\n",
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.47      0.37      0.41     58190\n",
      "         Low       0.49      0.20      0.29     52533\n",
      " Medium-High       0.49      0.65      0.56    109647\n",
      "  Medium-Low       0.47      0.50      0.49     82345\n",
      "\n",
      "    accuracy                           0.48    302715\n",
      "   macro avg       0.48      0.43      0.44    302715\n",
      "weighted avg       0.48      0.48      0.46    302715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtree_clf = DecisionTreeClassifier(max_depth = 15, criterion = 'gini')\n",
    "\n",
    "dtree_clf.fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred_1 = dtree_clf.predict(X_val_1)\n",
    "\n",
    "kn_acc = accuracy_score(y_val_1, y_pred_1)\n",
    "print(classification_report(y_val_1, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos resultados similares a los conseguidos con K-Nearest Neighbors, por lo que tampoco son excelentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/Desarrollo/DCC/Codigo-DCC/Mineria-CC5205/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/diego/Desarrollo/DCC/Codigo-DCC/Mineria-CC5205/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.22      0.02      0.03     58190\n",
      "         Low       0.00      0.00      0.00     52533\n",
      " Medium-High       0.37      0.85      0.52    109647\n",
      "  Medium-Low       0.29      0.17      0.21     82345\n",
      "\n",
      "    accuracy                           0.36    302715\n",
      "   macro avg       0.22      0.26      0.19    302715\n",
      "weighted avg       0.26      0.36      0.25    302715\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/Desarrollo/DCC/Codigo-DCC/Mineria-CC5205/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "nb_clf.fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred_1 = nb_clf.predict(X_val_1)\n",
    "\n",
    "kn_acc = accuracy_score(y_val_1, y_pred_1)\n",
    "print(classification_report(y_val_1, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui los resultados son terribles, incluso peores que el dummy classifier. Hay etiquetas que incluso no recibieron ninguna prediccion. Este clasificador se descarta para el conjunto de datos usado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/Desarrollo/DCC/Codigo-DCC/Mineria-CC5205/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/diego/Desarrollo/DCC/Codigo-DCC/Mineria-CC5205/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.29      0.00      0.00     58190\n",
      "         Low       0.00      0.00      0.00     52533\n",
      " Medium-High       0.36      1.00      0.53    109647\n",
      "  Medium-Low       0.00      0.00      0.00     82345\n",
      "\n",
      "    accuracy                           0.36    302715\n",
      "   macro avg       0.16      0.25      0.13    302715\n",
      "weighted avg       0.19      0.36      0.19    302715\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/Desarrollo/DCC/Codigo-DCC/Mineria-CC5205/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = LinearSVC()\n",
    "\n",
    "svm_clf.fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred_1 = svm_clf.predict(X_val_1)\n",
    "\n",
    "kn_acc = accuracy_score(y_val_1, y_pred_1)\n",
    "print(classification_report(y_val_1, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados aqui iguales o peores que los obtenidos con Naive Bayes. Este clasificador no sirve para este conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/Desarrollo/DCC/Codigo-DCC/Mineria-CC5205/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/diego/Desarrollo/DCC/Codigo-DCC/Mineria-CC5205/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.00      0.00      0.00     58190\n",
      "         Low       0.00      0.00      0.00     52533\n",
      " Medium-High       0.36      1.00      0.53    109647\n",
      "  Medium-Low       0.00      0.00      0.00     82345\n",
      "\n",
      "    accuracy                           0.36    302715\n",
      "   macro avg       0.09      0.25      0.13    302715\n",
      "weighted avg       0.13      0.36      0.19    302715\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/Desarrollo/DCC/Codigo-DCC/Mineria-CC5205/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(n_jobs = -1)\n",
    "\n",
    "sgd_clf.fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred_1 = sgd_clf.predict(X_val_1)\n",
    "\n",
    "kn_acc = accuracy_score(y_val_1, y_pred_1)\n",
    "print(classification_report(y_val_1, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un intento de encontrar un clasificador que funcione, probamos el uso de SGD (Stocastic Gradient Descent). Obtenemos resultados terribles que no nos sirven para la situacion actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado el conjunto limitado de atributos, el clasificador con el mejor desempeño fue Decision Tree. Sin embargo, los resultados dejan mucho que desear. Podemos concluir a priori que basados solo en los atributos asociados a la \"Popularidad\" no es posible hacer una prediccion de la positividad de una canción, o al menos no una que sea aceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ampliando el uso de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado el mal desempeño anterior, procederemos a ampliar el campo de atributos a utilizar.\n",
    "\n",
    "Esta vez ademas de \"streams\" y \"popularity\", utilizaremos \"af_danceability\", \"af_energy\", \"af_key\", \"af_loudness\", \"af_mode\", \"af_acousticness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util_2 = df_spotify[[\"streams\", \"popularity\", \"af_danceability\", \"af_energy\", \"af_key\", \"af_loudness\", \"af_mode\", \"af_acousticness\", \"af_valence\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>streams</th>\n",
       "      <th>popularity</th>\n",
       "      <th>af_danceability</th>\n",
       "      <th>af_energy</th>\n",
       "      <th>af_key</th>\n",
       "      <th>af_loudness</th>\n",
       "      <th>af_mode</th>\n",
       "      <th>af_acousticness</th>\n",
       "      <th>af_valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28838.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.411</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-10.319</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.688</td>\n",
       "      <td>10</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218751.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.853</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-2.975</td>\n",
       "      <td>10</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193855.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.758</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>10</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>179042.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.542</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-8.106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009045</th>\n",
       "      <td>11984.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.823</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-2.718</td>\n",
       "      <td>0</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009046</th>\n",
       "      <td>11904.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.375</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-9.185</td>\n",
       "      <td>10</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009047</th>\n",
       "      <td>11894.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.499</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-10.601</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009048</th>\n",
       "      <td>11751.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.824</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.483</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009049</th>\n",
       "      <td>11481.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.307</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.531</td>\n",
       "      <td>10</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009050 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          streams  popularity  af_danceability  af_energy  af_key  \\\n",
       "0         28838.0        44.0            0.068      0.411    11.0   \n",
       "1         22249.0         1.0            0.611      0.688     1.0   \n",
       "2        218751.0        64.0            0.606      0.853     9.0   \n",
       "3        193855.0        74.0            0.086      0.758    11.0   \n",
       "4        179042.0        72.0            0.795      0.542     6.0   \n",
       "...           ...         ...              ...        ...     ...   \n",
       "1009045   11984.0        22.0            0.824      0.823    11.0   \n",
       "1009046   11904.0        53.0            0.051      0.375     9.0   \n",
       "1009047   11894.0        45.0            0.534      0.499     9.0   \n",
       "1009048   11751.0         0.0            0.735      0.824     2.0   \n",
       "1009049   11481.0        49.0            0.544      0.307     1.0   \n",
       "\n",
       "         af_loudness  af_mode  af_acousticness  af_valence  \n",
       "0            -10.319        0            0.043       0.251  \n",
       "1             -5.688       10            0.264       0.393  \n",
       "2             -2.975       10            0.237       0.822  \n",
       "3             -0.516       10            0.021       0.453  \n",
       "4             -8.106        0            0.903       0.055  \n",
       "...              ...      ...              ...         ...  \n",
       "1009045       -2.718        0            0.197       0.855  \n",
       "1009046       -9.185       10            0.813       0.025  \n",
       "1009047      -10.601        0            0.416       0.227  \n",
       "1009048       -3.483        0            0.706       0.669  \n",
       "1009049      -10.531       10            0.814       0.329  \n",
       "\n",
       "[1009050 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el mismo proceso de etiquetado y escalado de la información que en la primera iteración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_etiquetado_2 = df_util_2.copy()\n",
    "\n",
    "df_etiquetado_2[\"af_valence\"] = df_etiquetado_2[\"af_valence\"].apply(apply_etiqueta)\n",
    "X_2 = df_etiquetado_2.drop(columns = 'af_valence')\n",
    "y_2 = df_etiquetado_2[\"af_valence\"]\n",
    "\n",
    "X_scaled_2 = pd.DataFrame(StandardScaler().fit_transform(X_2), columns = X_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>streams</th>\n",
       "      <th>popularity</th>\n",
       "      <th>af_danceability</th>\n",
       "      <th>af_energy</th>\n",
       "      <th>af_key</th>\n",
       "      <th>af_loudness</th>\n",
       "      <th>af_mode</th>\n",
       "      <th>af_acousticness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.209665</td>\n",
       "      <td>-0.391136</td>\n",
       "      <td>-2.345716</td>\n",
       "      <td>-0.740317</td>\n",
       "      <td>1.487257</td>\n",
       "      <td>-1.676977</td>\n",
       "      <td>-1.086527</td>\n",
       "      <td>-1.226130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.228652</td>\n",
       "      <td>-1.953110</td>\n",
       "      <td>-0.088171</td>\n",
       "      <td>0.483934</td>\n",
       "      <td>-1.217273</td>\n",
       "      <td>-0.031738</td>\n",
       "      <td>0.920363</td>\n",
       "      <td>-0.374582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.337597</td>\n",
       "      <td>0.335363</td>\n",
       "      <td>-0.108959</td>\n",
       "      <td>1.213180</td>\n",
       "      <td>0.946351</td>\n",
       "      <td>0.932100</td>\n",
       "      <td>0.920363</td>\n",
       "      <td>-0.478617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.265856</td>\n",
       "      <td>0.698613</td>\n",
       "      <td>-2.270880</td>\n",
       "      <td>0.793311</td>\n",
       "      <td>1.487257</td>\n",
       "      <td>1.805701</td>\n",
       "      <td>0.920363</td>\n",
       "      <td>-1.310900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.223170</td>\n",
       "      <td>0.625963</td>\n",
       "      <td>0.676817</td>\n",
       "      <td>-0.161339</td>\n",
       "      <td>0.134992</td>\n",
       "      <td>-0.890772</td>\n",
       "      <td>-1.086527</td>\n",
       "      <td>2.087586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009045</th>\n",
       "      <td>-0.258232</td>\n",
       "      <td>-1.190286</td>\n",
       "      <td>0.797385</td>\n",
       "      <td>1.080590</td>\n",
       "      <td>1.487257</td>\n",
       "      <td>1.023404</td>\n",
       "      <td>-1.086527</td>\n",
       "      <td>-0.632744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009046</th>\n",
       "      <td>-0.258463</td>\n",
       "      <td>-0.064212</td>\n",
       "      <td>-2.416394</td>\n",
       "      <td>-0.899425</td>\n",
       "      <td>0.946351</td>\n",
       "      <td>-1.274105</td>\n",
       "      <td>0.920363</td>\n",
       "      <td>1.740801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009047</th>\n",
       "      <td>-0.258492</td>\n",
       "      <td>-0.354812</td>\n",
       "      <td>-0.408302</td>\n",
       "      <td>-0.351385</td>\n",
       "      <td>0.946351</td>\n",
       "      <td>-1.777162</td>\n",
       "      <td>-1.086527</td>\n",
       "      <td>0.211098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009048</th>\n",
       "      <td>-0.258904</td>\n",
       "      <td>-1.989435</td>\n",
       "      <td>0.427364</td>\n",
       "      <td>1.085010</td>\n",
       "      <td>-0.946820</td>\n",
       "      <td>0.751625</td>\n",
       "      <td>-1.086527</td>\n",
       "      <td>1.328514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009049</th>\n",
       "      <td>-0.259682</td>\n",
       "      <td>-0.209512</td>\n",
       "      <td>-0.366726</td>\n",
       "      <td>-1.199963</td>\n",
       "      <td>-1.217273</td>\n",
       "      <td>-1.752293</td>\n",
       "      <td>0.920363</td>\n",
       "      <td>1.744655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009050 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          streams  popularity  af_danceability  af_energy    af_key  \\\n",
       "0       -0.209665   -0.391136        -2.345716  -0.740317  1.487257   \n",
       "1       -0.228652   -1.953110        -0.088171   0.483934 -1.217273   \n",
       "2        0.337597    0.335363        -0.108959   1.213180  0.946351   \n",
       "3        0.265856    0.698613        -2.270880   0.793311  1.487257   \n",
       "4        0.223170    0.625963         0.676817  -0.161339  0.134992   \n",
       "...           ...         ...              ...        ...       ...   \n",
       "1009045 -0.258232   -1.190286         0.797385   1.080590  1.487257   \n",
       "1009046 -0.258463   -0.064212        -2.416394  -0.899425  0.946351   \n",
       "1009047 -0.258492   -0.354812        -0.408302  -0.351385  0.946351   \n",
       "1009048 -0.258904   -1.989435         0.427364   1.085010 -0.946820   \n",
       "1009049 -0.259682   -0.209512        -0.366726  -1.199963 -1.217273   \n",
       "\n",
       "         af_loudness   af_mode  af_acousticness  \n",
       "0          -1.676977 -1.086527        -1.226130  \n",
       "1          -0.031738  0.920363        -0.374582  \n",
       "2           0.932100  0.920363        -0.478617  \n",
       "3           1.805701  0.920363        -1.310900  \n",
       "4          -0.890772 -1.086527         2.087586  \n",
       "...              ...       ...              ...  \n",
       "1009045     1.023404 -1.086527        -0.632744  \n",
       "1009046    -1.274105  0.920363         1.740801  \n",
       "1009047    -1.777162 -1.086527         0.211098  \n",
       "1009048     0.751625 -1.086527         1.328514  \n",
       "1009049    -1.752293  0.920363         1.744655  \n",
       "\n",
       "[1009050 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los conjuntos de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2, X_val_2, y_train_2, y_val_2 = train_test_split(X_scaled_2, y_2, test_size=0.3, random_state=0, stratify=y_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con una busqueda y optimizacion de parametros con GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación de parámetros:\n",
      "{'n_neighbors': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "tuned_parameters = {'n_neighbors': list(range(1, 16, 1)), 'weights': ['uniform', 'distance']}\n",
    "\n",
    "score = 'f1_macro'\n",
    "\n",
    "cls = KNeighborsClassifier(n_jobs = -1)\n",
    "\n",
    "clf = GridSearchCV(cls, param_grid = tuned_parameters, scoring = score, cv = 5)\n",
    "\n",
    "clf.fit(X_train_2, y_train_2)\n",
    "\n",
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      1.00      1.00     58190\n",
      "         Low       1.00      1.00      1.00     52533\n",
      " Medium-High       1.00      1.00      1.00    109647\n",
      "  Medium-Low       1.00      1.00      1.00     82345\n",
      "\n",
      "    accuracy                           1.00    302715\n",
      "   macro avg       1.00      1.00      1.00    302715\n",
      "weighted avg       1.00      1.00      1.00    302715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kn_clf_1 = KNeighborsClassifier(n_neighbors=1, weights = 'uniform', n_jobs = -1)\n",
    "\n",
    "kn_clf_1.fit(X_train_2, y_train_2)\n",
    "\n",
    "y_pred_2 = kn_clf_1.predict(X_val_2)\n",
    "\n",
    "kn_acc = accuracy_score(y_val_2, y_pred_2)\n",
    "print(classification_report(y_val_2, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras correr este experimento, es claro que o la informacion provista tiene correlaciones directas con la informacion buscada, o que este modelo esta demasiado over-fitted a la muestra de datos entregada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado lo anterior, vamos a reducir el scope de los atributos utilizados:\n",
    "\n",
    "Esta vez sólo utilizaremos: \"streams\", \"popularity\", \"af_loudness\" y \"af_tempo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util_3 = df_spotify[[\"streams\", \"popularity\", \"af_loudness\", \"af_tempo\", \"af_valence\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>streams</th>\n",
       "      <th>popularity</th>\n",
       "      <th>af_loudness</th>\n",
       "      <th>af_tempo</th>\n",
       "      <th>af_valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28838.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-10.319</td>\n",
       "      <td>115.024</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.688</td>\n",
       "      <td>178.462</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218751.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-2.975</td>\n",
       "      <td>178.043</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193855.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-0.516</td>\n",
       "      <td>97.014</td>\n",
       "      <td>0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>179042.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>-8.106</td>\n",
       "      <td>167.823</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009045</th>\n",
       "      <td>11984.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-2.718</td>\n",
       "      <td>140.014</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009046</th>\n",
       "      <td>11904.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-9.185</td>\n",
       "      <td>132.552</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009047</th>\n",
       "      <td>11894.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>-10.601</td>\n",
       "      <td>91.954</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009048</th>\n",
       "      <td>11751.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.483</td>\n",
       "      <td>95.972</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009049</th>\n",
       "      <td>11481.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>-10.531</td>\n",
       "      <td>149.877</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009050 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          streams  popularity  af_loudness  af_tempo  af_valence\n",
       "0         28838.0        44.0      -10.319   115.024       0.251\n",
       "1         22249.0         1.0       -5.688   178.462       0.393\n",
       "2        218751.0        64.0       -2.975   178.043       0.822\n",
       "3        193855.0        74.0       -0.516    97.014       0.453\n",
       "4        179042.0        72.0       -8.106   167.823       0.055\n",
       "...           ...         ...          ...       ...         ...\n",
       "1009045   11984.0        22.0       -2.718   140.014       0.855\n",
       "1009046   11904.0        53.0       -9.185   132.552       0.025\n",
       "1009047   11894.0        45.0      -10.601    91.954       0.227\n",
       "1009048   11751.0         0.0       -3.483    95.972       0.669\n",
       "1009049   11481.0        49.0      -10.531   149.877       0.329\n",
       "\n",
       "[1009050 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos el proceso de etiquetado y escalado de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_etiquetado_3 = df_util_3.copy()\n",
    "\n",
    "df_etiquetado_3[\"af_valence\"] = df_etiquetado_3[\"af_valence\"].apply(apply_etiqueta)\n",
    "X_3 = df_etiquetado_3.drop(columns = 'af_valence')\n",
    "y_3 = df_etiquetado_3[\"af_valence\"]\n",
    "\n",
    "X_scaled_3 = pd.DataFrame(StandardScaler().fit_transform(X_3), columns = X_3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>streams</th>\n",
       "      <th>popularity</th>\n",
       "      <th>af_loudness</th>\n",
       "      <th>af_tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.209665</td>\n",
       "      <td>-0.391136</td>\n",
       "      <td>-1.676977</td>\n",
       "      <td>0.027485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.228652</td>\n",
       "      <td>-1.953110</td>\n",
       "      <td>-0.031738</td>\n",
       "      <td>1.497668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.337597</td>\n",
       "      <td>0.335363</td>\n",
       "      <td>0.932100</td>\n",
       "      <td>1.487958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.265856</td>\n",
       "      <td>0.698613</td>\n",
       "      <td>1.805701</td>\n",
       "      <td>-0.389899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.223170</td>\n",
       "      <td>0.625963</td>\n",
       "      <td>-0.890772</td>\n",
       "      <td>1.251108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009045</th>\n",
       "      <td>-0.258232</td>\n",
       "      <td>-1.190286</td>\n",
       "      <td>1.023404</td>\n",
       "      <td>0.606631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009046</th>\n",
       "      <td>-0.258463</td>\n",
       "      <td>-0.064212</td>\n",
       "      <td>-1.274105</td>\n",
       "      <td>0.433699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009047</th>\n",
       "      <td>-0.258492</td>\n",
       "      <td>-0.354812</td>\n",
       "      <td>-1.777162</td>\n",
       "      <td>-0.507165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009048</th>\n",
       "      <td>-0.258904</td>\n",
       "      <td>-1.989435</td>\n",
       "      <td>0.751625</td>\n",
       "      <td>-0.414047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009049</th>\n",
       "      <td>-0.259682</td>\n",
       "      <td>-0.209512</td>\n",
       "      <td>-1.752293</td>\n",
       "      <td>0.835208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009050 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          streams  popularity  af_loudness  af_tempo\n",
       "0       -0.209665   -0.391136    -1.676977  0.027485\n",
       "1       -0.228652   -1.953110    -0.031738  1.497668\n",
       "2        0.337597    0.335363     0.932100  1.487958\n",
       "3        0.265856    0.698613     1.805701 -0.389899\n",
       "4        0.223170    0.625963    -0.890772  1.251108\n",
       "...           ...         ...          ...       ...\n",
       "1009045 -0.258232   -1.190286     1.023404  0.606631\n",
       "1009046 -0.258463   -0.064212    -1.274105  0.433699\n",
       "1009047 -0.258492   -0.354812    -1.777162 -0.507165\n",
       "1009048 -0.258904   -1.989435     0.751625 -0.414047\n",
       "1009049 -0.259682   -0.209512    -1.752293  0.835208\n",
       "\n",
       "[1009050 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, X_val_3, y_train_3, y_val_3 = train_test_split(X_scaled_3, y_3, test_size=0.3, random_state=0, stratify=y_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos un baseline para evaluar los clasificadores:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.19      0.19      0.19     58190\n",
      "         Low       0.17      0.17      0.17     52533\n",
      " Medium-High       0.36      0.36      0.36    109647\n",
      "  Medium-Low       0.27      0.27      0.27     82345\n",
      "\n",
      "    accuracy                           0.27    302715\n",
      "   macro avg       0.25      0.25      0.25    302715\n",
      "weighted avg       0.27      0.27      0.27    302715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy = 'stratified')\n",
    "\n",
    "dummy_clf.fit(X_train_3, y_train_3)\n",
    "\n",
    "y_pred_3 = dummy_clf.predict(X_val_3)\n",
    "\n",
    "kn_acc = accuracy_score(y_val_3, y_pred_3)\n",
    "print(classification_report(y_val_3, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación de parámetros:\n",
      "{'n_neighbors': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "tuned_parameters = {'n_neighbors': list(range(1, 16, 1)), 'weights': ['uniform', 'distance']}\n",
    "\n",
    "score = 'f1_macro'\n",
    "\n",
    "cls = KNeighborsClassifier(n_jobs = -1)\n",
    "\n",
    "clf = GridSearchCV(cls, param_grid = tuned_parameters, scoring = score, cv = 5)\n",
    "\n",
    "clf.fit(X_train_3, y_train_3)\n",
    "\n",
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.99      0.99      0.99     58190\n",
      "         Low       0.99      0.99      0.99     52533\n",
      " Medium-High       0.99      0.99      0.99    109647\n",
      "  Medium-Low       0.99      0.99      0.99     82345\n",
      "\n",
      "    accuracy                           0.99    302715\n",
      "   macro avg       0.99      0.99      0.99    302715\n",
      "weighted avg       0.99      0.99      0.99    302715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kn_clf_1 = KNeighborsClassifier(n_neighbors=1, weights = 'uniform', n_jobs = -1)\n",
    "\n",
    "kn_clf_1.fit(X_train_3, y_train_3)\n",
    "\n",
    "y_pred_3 = kn_clf_1.predict(X_val_3)\n",
    "\n",
    "kn_acc = accuracy_score(y_val_3, y_pred_3)\n",
    "print(classification_report(y_val_3, y_pred_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aun habiendo reducido el scope de atributos utilizados, el resultado esta demasiado ajustado a los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un ultimo intento por mejorar la situación, vamos a remover el atributo \"af_loudness\" y probar como sigue la situación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util_4 = df_spotify[[\"streams\", \"popularity\", \"af_tempo\", \"af_valence\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>streams</th>\n",
       "      <th>popularity</th>\n",
       "      <th>af_tempo</th>\n",
       "      <th>af_valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28838.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>115.024</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.462</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>218751.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>178.043</td>\n",
       "      <td>0.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193855.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>97.014</td>\n",
       "      <td>0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>179042.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>167.823</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009045</th>\n",
       "      <td>11984.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>140.014</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009046</th>\n",
       "      <td>11904.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>132.552</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009047</th>\n",
       "      <td>11894.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>91.954</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009048</th>\n",
       "      <td>11751.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.972</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009049</th>\n",
       "      <td>11481.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>149.877</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009050 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          streams  popularity  af_tempo  af_valence\n",
       "0         28838.0        44.0   115.024       0.251\n",
       "1         22249.0         1.0   178.462       0.393\n",
       "2        218751.0        64.0   178.043       0.822\n",
       "3        193855.0        74.0    97.014       0.453\n",
       "4        179042.0        72.0   167.823       0.055\n",
       "...           ...         ...       ...         ...\n",
       "1009045   11984.0        22.0   140.014       0.855\n",
       "1009046   11904.0        53.0   132.552       0.025\n",
       "1009047   11894.0        45.0    91.954       0.227\n",
       "1009048   11751.0         0.0    95.972       0.669\n",
       "1009049   11481.0        49.0   149.877       0.329\n",
       "\n",
       "[1009050 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente etiquetamos y escalamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_etiquetado_4 = df_util_4.copy()\n",
    "\n",
    "df_etiquetado_4[\"af_valence\"] = df_etiquetado_4[\"af_valence\"].apply(apply_etiqueta)\n",
    "X_4 = df_etiquetado_4.drop(columns = 'af_valence')\n",
    "y_4 = df_etiquetado_4[\"af_valence\"]\n",
    "\n",
    "X_scaled_4 = pd.DataFrame(StandardScaler().fit_transform(X_4), columns = X_4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>streams</th>\n",
       "      <th>popularity</th>\n",
       "      <th>af_tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.209665</td>\n",
       "      <td>-0.391136</td>\n",
       "      <td>0.027485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.228652</td>\n",
       "      <td>-1.953110</td>\n",
       "      <td>1.497668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.337597</td>\n",
       "      <td>0.335363</td>\n",
       "      <td>1.487958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.265856</td>\n",
       "      <td>0.698613</td>\n",
       "      <td>-0.389899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.223170</td>\n",
       "      <td>0.625963</td>\n",
       "      <td>1.251108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009045</th>\n",
       "      <td>-0.258232</td>\n",
       "      <td>-1.190286</td>\n",
       "      <td>0.606631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009046</th>\n",
       "      <td>-0.258463</td>\n",
       "      <td>-0.064212</td>\n",
       "      <td>0.433699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009047</th>\n",
       "      <td>-0.258492</td>\n",
       "      <td>-0.354812</td>\n",
       "      <td>-0.507165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009048</th>\n",
       "      <td>-0.258904</td>\n",
       "      <td>-1.989435</td>\n",
       "      <td>-0.414047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009049</th>\n",
       "      <td>-0.259682</td>\n",
       "      <td>-0.209512</td>\n",
       "      <td>0.835208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009050 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          streams  popularity  af_tempo\n",
       "0       -0.209665   -0.391136  0.027485\n",
       "1       -0.228652   -1.953110  1.497668\n",
       "2        0.337597    0.335363  1.487958\n",
       "3        0.265856    0.698613 -0.389899\n",
       "4        0.223170    0.625963  1.251108\n",
       "...           ...         ...       ...\n",
       "1009045 -0.258232   -1.190286  0.606631\n",
       "1009046 -0.258463   -0.064212  0.433699\n",
       "1009047 -0.258492   -0.354812 -0.507165\n",
       "1009048 -0.258904   -1.989435 -0.414047\n",
       "1009049 -0.259682   -0.209512  0.835208\n",
       "\n",
       "[1009050 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4, X_val_4, y_train_4, y_val_4 = train_test_split(X_scaled_4, y_4, test_size=0.3, random_state=0, stratify=y_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a establecer baseline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.19      0.19      0.19     58190\n",
      "         Low       0.17      0.17      0.17     52533\n",
      " Medium-High       0.36      0.36      0.36    109647\n",
      "  Medium-Low       0.27      0.27      0.27     82345\n",
      "\n",
      "    accuracy                           0.27    302715\n",
      "   macro avg       0.25      0.25      0.25    302715\n",
      "weighted avg       0.27      0.27      0.27    302715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy = 'stratified')\n",
    "\n",
    "dummy_clf.fit(X_train_4, y_train_4)\n",
    "\n",
    "y_pred_4 = dummy_clf.predict(X_val_4)\n",
    "\n",
    "kn_acc = accuracy_score(y_val_4, y_pred_4)\n",
    "print(classification_report(y_val_4, y_pred_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación de parámetros:\n",
      "{'n_neighbors': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "tuned_parameters = {'n_neighbors': list(range(1, 16, 1)), 'weights': ['uniform', 'distance']}\n",
    "\n",
    "score = 'f1_macro'\n",
    "\n",
    "cls = KNeighborsClassifier(n_jobs = -1)\n",
    "\n",
    "clf = GridSearchCV(cls, param_grid = tuned_parameters, scoring = score, cv = 5)\n",
    "\n",
    "clf.fit(X_train_4, y_train_4)\n",
    "\n",
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.96      0.96      0.96     58190\n",
      "         Low       0.95      0.95      0.95     52533\n",
      " Medium-High       0.96      0.96      0.96    109647\n",
      "  Medium-Low       0.96      0.95      0.95     82345\n",
      "\n",
      "    accuracy                           0.96    302715\n",
      "   macro avg       0.96      0.96      0.96    302715\n",
      "weighted avg       0.96      0.96      0.96    302715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kn_clf_2 = KNeighborsClassifier(n_neighbors=2, weights = 'distance', n_jobs = -1)\n",
    "\n",
    "kn_clf_2.fit(X_train_4, y_train_4)\n",
    "\n",
    "y_pred_4 = kn_clf_2.predict(X_val_4)\n",
    "\n",
    "kn_acc = accuracy_score(y_val_4, y_pred_4)\n",
    "print(classification_report(y_val_4, y_pred_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados esta vez son buenos, pero sin llegar al nivel de overfit que se presentaba en las situaciones anteriores.\n",
    "Creemos que este es un buen modelo para responder a la pregunta buscada.\n",
    "\n",
    "Dados estos resultados, la pregunta se puede reformular:\n",
    "\n",
    "- ¿Es posible predecir la positividad de una cancion basandose en su popularidad y tempo?\n",
    "\n",
    "A lo cual podemos responder con un alto grado de certeza que si, en efecto es posible, y con muy buenos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 2:\n",
    "- ¿Es posible asociar el valor de energía u otros parámetros de una canción, con la región geográfica en donde es más popular?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#juntar paises en base al continente\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P2 = df_spotify.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero modificamos la información de la columna regiones para reducir las clases al agrupar los países por regiones geográficas más amplia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = [\n",
    "    (['Morocco','South Africa'],'Africa'),\n",
    "    (['Argentina','Bolivia','Brazil','Chile','Colombia','Costa Rica','Dominican Republic','Ecuador','El Salvador','Guatemala','Honduras','Mexico','Nicaragua','Panama','Paraguay','Peru','Uruguay'],'America_latina'),\n",
    "    (['Canada','United States'],'America_norte'),\n",
    "    (['Hong Kong','India','Indonesia','Japan','Malaysia','Philippines','Singapore','Taiwan','Thailand','Vietnam'],'Asia'),\n",
    "    (['Andorra','Austria','Belgium','Bulgaria','Czech Republic','Denmark','Estonia','Finland','France','Germany','Greece','Hungary','Iceland','Ireland','Italy','Latvia','Lithuania','Luxembourg',\n",
    "     'Netherlands','Norway','Poland','Portugal','Romania','Russia','Slovakia','Spain','Sweden','Switzerland','Ukraine','United Kingdom'],'Europa'),\n",
    "    (['Australia','New Zealand'],'Oceania'),\n",
    "    (['Egypt','Israel','Saudi Arabia','Turkey','United Arab Emirates'],'Oriente_medio')\n",
    "]\n",
    "\n",
    "def apply_etiqueta(elemento):\n",
    "    for i in d1:\n",
    "        if elemento in i[0]:\n",
    "            return i[1]\n",
    "        \n",
    "new_reg = df_P2[\"region\"]\n",
    "\n",
    "\n",
    "for index, row in df_P2.iterrows():\n",
    "    new_data = apply_etiqueta(row[\"region\"])\n",
    "    new_reg.iat[index] = new_data\n",
    "\n",
    "#se reemplaza la columa de region\n",
    "df_P2[\"region\"] = new_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar si esta relación existe vamos a usar un Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos atributo por atributo probando para ver cual tiene mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af_danceability\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.42      0.02      0.03      1785\n",
      "America_latina       0.53      0.50      0.52     15151\n",
      " America_norte       0.88      0.00      0.01      1785\n",
      "          Asia       0.52      0.26      0.35      8921\n",
      "        Europa       0.51      0.80      0.62     25448\n",
      "       Oceania       0.53      0.01      0.03      1785\n",
      " Oriente_medio       0.46      0.04      0.07      4462\n",
      "\n",
      "      accuracy                           0.51     59337\n",
      "     macro avg       0.55      0.23      0.23     59337\n",
      "  weighted avg       0.52      0.51      0.46     59337\n",
      "\n",
      "af_energy\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.56      0.02      0.03      1785\n",
      "America_latina       0.55      0.53      0.54     15151\n",
      " America_norte       0.31      0.01      0.02      1785\n",
      "          Asia       0.51      0.28      0.36      8921\n",
      "        Europa       0.52      0.80      0.63     25448\n",
      "       Oceania       0.45      0.02      0.05      1785\n",
      " Oriente_medio       0.51      0.03      0.06      4462\n",
      "\n",
      "      accuracy                           0.53     59337\n",
      "     macro avg       0.49      0.24      0.24     59337\n",
      "  weighted avg       0.52      0.53      0.47     59337\n",
      "\n",
      "af_key\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.00      0.00      0.00      1785\n",
      "America_latina       0.00      0.00      0.00     15151\n",
      " America_norte       0.00      0.00      0.00      1785\n",
      "          Asia       0.00      0.00      0.00      8921\n",
      "        Europa       0.43      1.00      0.60     25448\n",
      "       Oceania       0.00      0.00      0.00      1785\n",
      " Oriente_medio       0.00      0.00      0.00      4462\n",
      "\n",
      "      accuracy                           0.43     59337\n",
      "     macro avg       0.06      0.14      0.09     59337\n",
      "  weighted avg       0.18      0.43      0.26     59337\n",
      "\n",
      "af_loudness\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.79      0.39      0.52      1785\n",
      "America_latina       0.75      0.71      0.73     15151\n",
      " America_norte       0.55      0.12      0.20      1785\n",
      "          Asia       0.75      0.57      0.65      8921\n",
      "        Europa       0.64      0.88      0.74     25448\n",
      "       Oceania       0.67      0.18      0.28      1785\n",
      " Oriente_medio       0.71      0.28      0.41      4462\n",
      "\n",
      "      accuracy                           0.68     59337\n",
      "     macro avg       0.70      0.45      0.50     59337\n",
      "  weighted avg       0.69      0.68      0.66     59337\n",
      "\n",
      "af_mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.00      0.00      0.00      1785\n",
      "America_latina       0.00      0.00      0.00     15151\n",
      " America_norte       0.00      0.00      0.00      1785\n",
      "          Asia       0.00      0.00      0.00      8921\n",
      "        Europa       0.43      1.00      0.60     25448\n",
      "       Oceania       0.00      0.00      0.00      1785\n",
      " Oriente_medio       0.00      0.00      0.00      4462\n",
      "\n",
      "      accuracy                           0.43     59337\n",
      "     macro avg       0.06      0.14      0.09     59337\n",
      "  weighted avg       0.18      0.43      0.26     59337\n",
      "\n",
      "af_speechiness\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.50      0.07      0.13      1785\n",
      "America_latina       0.56      0.51      0.54     15151\n",
      " America_norte       0.24      0.00      0.00      1785\n",
      "          Asia       0.49      0.25      0.33      8921\n",
      "        Europa       0.52      0.82      0.64     25448\n",
      "       Oceania       0.63      0.02      0.04      1785\n",
      " Oriente_medio       0.42      0.03      0.05      4462\n",
      "\n",
      "      accuracy                           0.53     59337\n",
      "     macro avg       0.48      0.25      0.25     59337\n",
      "  weighted avg       0.51      0.53      0.47     59337\n",
      "\n",
      "af_acousticness\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.47      0.04      0.08      1785\n",
      "America_latina       0.56      0.51      0.53     15151\n",
      " America_norte       0.29      0.01      0.02      1785\n",
      "          Asia       0.53      0.27      0.36      8921\n",
      "        Europa       0.52      0.82      0.64     25448\n",
      "       Oceania       0.42      0.02      0.04      1785\n",
      " Oriente_medio       0.44      0.04      0.07      4462\n",
      "\n",
      "      accuracy                           0.53     59337\n",
      "     macro avg       0.46      0.24      0.25     59337\n",
      "  weighted avg       0.51      0.53      0.47     59337\n",
      "\n",
      "af_liveness\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.50      0.06      0.11      1785\n",
      "America_latina       0.54      0.47      0.50     15151\n",
      " America_norte       0.43      0.01      0.02      1785\n",
      "          Asia       0.44      0.18      0.26      8921\n",
      "        Europa       0.50      0.82      0.62     25448\n",
      "       Oceania       0.51      0.06      0.11      1785\n",
      " Oriente_medio       0.39      0.04      0.08      4462\n",
      "\n",
      "      accuracy                           0.51     59337\n",
      "     macro avg       0.47      0.24      0.24     59337\n",
      "  weighted avg       0.49      0.51      0.45     59337\n",
      "\n",
      "af_valence\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.38      0.04      0.07      1785\n",
      "America_latina       0.61      0.51      0.56     15151\n",
      " America_norte       0.43      0.01      0.01      1785\n",
      "          Asia       0.50      0.27      0.35      8921\n",
      "        Europa       0.52      0.84      0.64     25448\n",
      "       Oceania       0.48      0.01      0.02      1785\n",
      " Oriente_medio       0.34      0.02      0.05      4462\n",
      "\n",
      "      accuracy                           0.54     59337\n",
      "     macro avg       0.47      0.24      0.24     59337\n",
      "  weighted avg       0.52      0.54      0.48     59337\n",
      "\n",
      "af_tempo\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.85      0.40      0.54      1785\n",
      "America_latina       0.79      0.72      0.75     15151\n",
      " America_norte       0.65      0.16      0.25      1785\n",
      "          Asia       0.80      0.62      0.70      8921\n",
      "        Europa       0.66      0.90      0.76     25448\n",
      "       Oceania       0.78      0.21      0.33      1785\n",
      " Oriente_medio       0.77      0.33      0.46      4462\n",
      "\n",
      "      accuracy                           0.71     59337\n",
      "     macro avg       0.76      0.48      0.54     59337\n",
      "  weighted avg       0.73      0.71      0.69     59337\n",
      "\n",
      "af_time_signature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.00      0.00      0.00      1785\n",
      "America_latina       0.00      0.00      0.00     15151\n",
      " America_norte       0.00      0.00      0.00      1785\n",
      "          Asia       0.00      0.00      0.00      8921\n",
      "        Europa       0.43      1.00      0.60     25448\n",
      "       Oceania       0.00      0.00      0.00      1785\n",
      " Oriente_medio       0.00      0.00      0.00      4462\n",
      "\n",
      "      accuracy                           0.43     59337\n",
      "     macro avg       0.06      0.14      0.09     59337\n",
      "  weighted avg       0.18      0.43      0.26     59337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ['af_danceability','af_energy', 'af_key', 'af_loudness', 'af_mode', 'af_speechiness','af_acousticness', 'af_liveness', 'af_valence','af_tempo', 'af_time_signature']:\n",
    "\n",
    "    df_P2 = df_P2.dropna(subset=[\"region\", i])  # Drop rows where target or feature is NaN\n",
    "    X = df_P2[i].copy().values.reshape(-1, 1)\n",
    "    y = df_P2[\"region\"]\n",
    "\n",
    "    #primero separamos los datos de entrenamiento y validacion/test\n",
    "    X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X,y,test_size=0.3,random_state=0,stratify=y)\n",
    "\n",
    "    # Luego separamos los datos de validación y pruebas                                       0.5 x 0.3 = 0.15\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=0, stratify=y_val_and_test)\n",
    "\n",
    "    #estandarizacion de datos, transformar los datos de manera que tengan media 0 y desviacion estandar 1.\n",
    "    std_scaler = StandardScaler()\n",
    "    X_train_std_scaled = std_scaler.fit_transform(X_train)\n",
    "\n",
    "    X_val_std_scaled = std_scaler.transform(X_val)\n",
    "    X_test_std_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "    #definimos nuestro modelo\n",
    "    clf = DecisionTreeClassifier(criterion=\"gini\",random_state=0)\n",
    "\n",
    "    #entrenamos al modelo con fit\n",
    "    clf.fit(X_train_std_scaled, y_train)   ## Entrenar usando X (features), y (clase)\n",
    "\n",
    "    #realizamos predicciones de nuestros datos con los datos de validación\n",
    "    y_val_pred = clf.predict(X_val_std_scaled)\n",
    "\n",
    "\n",
    "    #metricas de las predicciones\n",
    "    print(i)\n",
    "    print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De lo anterior se pude observar que las dos características que presentan mayor relación son loudness y tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probamos con todas las características a la vez para ver si se encuentra un mejor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P2 = df_P2.dropna(subset=[\"region\", i])  # Drop rows where target or feature is NaN\n",
    "X = df_P2[['af_danceability','af_energy', 'af_key', 'af_loudness', 'af_mode', 'af_speechiness','af_acousticness', 'af_liveness', 'af_valence','af_tempo', 'af_time_signature']].copy()\n",
    "y = df_P2[\"region\"]\n",
    "\n",
    "#primero separamos los datos de entrenamiento y validacion/test\n",
    "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X,y,test_size=0.3,random_state=0,stratify=y)\n",
    "\n",
    "# Luego separamos los datos de validación y pruebas                                       0.5 x 0.3 = 0.15\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=0, stratify=y_val_and_test)\n",
    "\n",
    "#estandarizacion de datos, transformar los datos de manera que tengan media 0 y desviacion estandar 1.\n",
    "std_scaler = StandardScaler()\n",
    "X_train_std_scaled = std_scaler.fit_transform(X_train)\n",
    "\n",
    "X_val_std_scaled = std_scaler.transform(X_val)\n",
    "X_test_std_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "#definimos nuestro modelo\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\",random_state=0)\n",
    "\n",
    "#entrenamos al modelo con fit\n",
    "clf.fit(X_train_std_scaled, y_train)   ## Entrenar usando X (features), y (clase)\n",
    "\n",
    "#realizamos predicciones de nuestros datos con los datos de validación\n",
    "y_val_pred = clf.predict(X_val_std_scaled)\n",
    "\n",
    "\n",
    "#metricas de las predicciones\n",
    "print(\"todas\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es mejor que cualquiera de los intentos individuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se hará con los dos mejores resultados anteriores a la vez por si al agregar todos los dados se está perdiendo algo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af_loudness y af_tempo\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.94      0.48      0.64      1785\n",
      "America_latina       0.82      0.75      0.78     15151\n",
      " America_norte       0.64      0.19      0.29      1785\n",
      "          Asia       0.87      0.68      0.76      8921\n",
      "        Europa       0.68      0.92      0.78     25448\n",
      "       Oceania       0.83      0.25      0.39      1785\n",
      " Oriente_medio       0.86      0.38      0.52      4462\n",
      "\n",
      "      accuracy                           0.75     59337\n",
      "     macro avg       0.81      0.52      0.59     59337\n",
      "  weighted avg       0.77      0.75      0.73     59337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_P2 = df_P2.dropna(subset=[\"region\", i])  # Drop rows where target or feature is NaN\n",
    "X = df_P2[[\"af_loudness\",\"af_tempo\"]].copy()\n",
    "y = df_P2[\"region\"]\n",
    "\n",
    "#primero separamos los datos de entrenamiento y validacion/test\n",
    "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X,y,test_size=0.3,random_state=0,stratify=y)\n",
    "\n",
    "# Luego separamos los datos de validación y pruebas                                       0.5 x 0.3 = 0.15\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=0, stratify=y_val_and_test)\n",
    "\n",
    "#estandarizacion de datos, transformar los datos de manera que tengan media 0 y desviacion estandar 1.\n",
    "std_scaler = StandardScaler()\n",
    "X_train_std_scaled = std_scaler.fit_transform(X_train)\n",
    "\n",
    "X_val_std_scaled = std_scaler.transform(X_val)\n",
    "X_test_std_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "#definimos nuestro modelo\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\",random_state=0)\n",
    "\n",
    "#entrenamos al modelo con fit\n",
    "clf.fit(X_train_std_scaled, y_train)   ## Entrenar usando X (features), y (clase)\n",
    "\n",
    "#realizamos predicciones de nuestros datos con los datos de validación\n",
    "y_val_pred = clf.predict(X_val_std_scaled)\n",
    "\n",
    "\n",
    "#metricas de las predicciones\n",
    "print(\"af_loudness y af_tempo\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La con mejor resultado sigue siendo loudness y key, al parecer al agregar el resto de los datos no suma ni resta al resultado por lo tanto tomares el de los dos mejores para el test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todas\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.94      0.46      0.62      1785\n",
      "America_latina       0.82      0.75      0.78     15151\n",
      " America_norte       0.64      0.17      0.27      1785\n",
      "          Asia       0.88      0.67      0.76      8922\n",
      "        Europa       0.68      0.92      0.78     25448\n",
      "       Oceania       0.83      0.22      0.35      1785\n",
      " Oriente_medio       0.87      0.38      0.53      4461\n",
      "\n",
      "      accuracy                           0.74     59337\n",
      "     macro avg       0.81      0.51      0.59     59337\n",
      "  weighted avg       0.77      0.74      0.73     59337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#realizamos predicciones de nuestros datos con los datos de validación\n",
    "y_test_pred = clf.predict(X_test_std_scaled)\n",
    "\n",
    "\n",
    "#metricas de las predicciones\n",
    "print(\"todas\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se podría seguir experimentando al buscar alguna otra combinación de características que den un mejor resultado, pero tomar demasiado tiempo al ser demasiado combinaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 3:\n",
    "- ¿Qué parámetros son más adecuados para predecir la popularidad de una canción?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text = re.sub(r\"[0-9]\", \" \", text)\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def remove_unprintable_(text):\n",
    "    printable = set(string.printable + \"ñáéíóúü\" + \"ÑÁÉÍÓÚÜ\")\n",
    "    text = \"\".join(filter(lambda x: x in printable, text))\n",
    "    return text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    pattern = re.compile(r\"[^\\w\\sáéíóúüñÁÉÍÓÚÜÑ]\")\n",
    "    t = pattern.sub(r\" \", text)\n",
    "    return re.sub(\" +\", \" \", t)\n",
    "\n",
    "def reduce_spam(text):\n",
    "    text = re.sub(r\"(\\w+)(\\s+\\1){2,}\", r\"\\1\", text)\n",
    "    text = re.sub(r\"(\\w+\\s+\\w+)(\\s+\\1){2,}\", r\"\\1\", text)\n",
    "    return text\n",
    "\n",
    "def remove_vowels_accents(text):\n",
    "    return (\n",
    "        text.replace(\"á\", \"a\")\n",
    "        .replace(\"é\", \"e\")\n",
    "        .replace(\"í\", \"i\")\n",
    "        .replace(\"ó\", \"o\")\n",
    "        .replace(\"ú\", \"u\")\n",
    "        .replace(\"ü\", \"u\")\n",
    "    )\n",
    "\n",
    "def remove_stopwords(text, stopwords_list):\n",
    "    return \" \".join(\n",
    "        [word for word in str(text).split() if word not in stopwords_list]\n",
    "    )\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Alir3z4/stop-words/master/spanish.txt\"\n",
    "r = requests.get(url)\n",
    "\n",
    "stopwords_list = r.text.splitlines()\n",
    "\n",
    "def preprocesar(text):\n",
    "    text = text.lower()\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_unprintable_(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = reduce_spam(text)\n",
    "    text = remove_stopwords(text, stopwords_list)\n",
    "    text = remove_vowels_accents(text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P3 = df_spotify.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea del experimento asociado a la pregunta 3 es predecir la popularidad de la canción considerando su composición en términos numéricos, esto es considerando: valencia, tempo, acordes, ritmo, duración, etc. Se considera que hay información que no es relevante para la predicción como “url”, “track”, “album”, etc. Esta información no está incluida en el análisis, y debido a que el nombre del artista es una variable que influye directamente en la popularidad esta se excluye también. La única variable no numérica es “region”. \n",
    "Antes de realizar el preprocesamiento y posterior entrenamiento se determinan rangos de popularidad según los cuartiles de la popularidad en el dataset, con la intención de clasificar los datos en rangos de popularidad.\n",
    "Se realiza un preprocesamiento para vectorizar el texto y se estandarizan los valores numéricos, se utiliza como modelo un random forest y todo esto se implementa en un pipeline como se detalla a continuación. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quitamos las columnas con información no relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_P3=df_P3.drop(columns=['date','url','chart', 'track_id','available_markets','Año','Día','Column1','release_date','explicit','title','artist','trend','album','af_mode','rank','af_time_signature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos una medida para clasificar la popularidad por rangos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuartiles = df_P3['popularity'].quantile([0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos una muestra del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2000 = df_P3.head(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos otra forma de escribir la popularidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pop = df_2000['popularity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificamos la popularidad en rangos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_13276\\748377976.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Medium-Low' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  new_pop.iat[index] = 'Medium-Low'\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_13276\\748377976.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_pop.iat[index] = 'Medium-Low'\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_13276\\748377976.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_pop.iat[index] = 'Low'\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_13276\\748377976.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_pop.iat[index] = 'Medium'\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_13276\\748377976.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_pop.iat[index] = 'High'\n"
     ]
    }
   ],
   "source": [
    "for index, row in df_2000.iterrows():\n",
    "    if row['popularity']>=cuartiles[0.75]:\n",
    "        new_pop.iat[index] = 'High'\n",
    "    elif row['popularity']>=cuartiles[0.50]:\n",
    "        new_pop.iat[index] = 'Medium'\n",
    "    elif row['popularity']>=cuartiles[0.25]:\n",
    "        new_pop.iat[index] = 'Medium-Low'\n",
    "    else:\n",
    "        new_pop.iat[index] = 'Low'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazamos la columna de popularidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_13276\\22764449.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2000['popularity'] = new_pop\n"
     ]
    }
   ],
   "source": [
    "df_2000['popularity'].astype(str)\n",
    "df_2000['popularity'] = new_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos la nueva clasificación a un número"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_13276\\1181775591.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2000['popularity'] = le.fit_transform(df_2000['popularity'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_2000['popularity'] = le.fit_transform(df_2000['popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "features = ['region','streams','duration_ms', 'af_danceability', 'af_energy', 'af_key', 'af_loudness', 'af_speechiness', \n",
    "            'af_acousticness', 'af_instrumentalness', 'af_liveness', 'af_valence', 'af_tempo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparamos el dataset para entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_2000[features]\n",
    "y = df_2000['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=0, stratify=y_val_and_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos un pipeline para:\n",
    "- Transformar texto\n",
    "- Estandarizar los datos\n",
    "- Aplicar un clasificador (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Define tus columnas\n",
    "text_feature = 'region'\n",
    "numeric_features = ['streams', 'duration_ms', 'af_danceability', 'af_energy', 'af_key', \n",
    "                    'af_loudness', 'af_speechiness', 'af_acousticness', 'af_instrumentalness', \n",
    "                    'af_liveness', 'af_valence', 'af_tempo']\n",
    "\n",
    "# Crear la pipeline completa\n",
    "clf_pipeline = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('text', Pipeline([\n",
    "                ('vectorizer', CountVectorizer(min_df=1, preprocessor = preprocesar)),\n",
    "                ('to_dense', FunctionTransformer(lambda x: x.toarray(), accept_sparse=True))\n",
    "            ]), text_feature),\n",
    "            ('num', StandardScaler(), numeric_features)\n",
    "        ])),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                                   CountVectorizer(preprocessor=&lt;function preprocesar at 0x000001DA3AB40360&gt;)),\n",
       "                                                                  (&#x27;to_dense&#x27;,\n",
       "                                                                   FunctionTransformer(accept_sparse=True,\n",
       "                                                                                       func=&lt;function &lt;lambda&gt; at 0x000001DA1CA90040&gt;))]),\n",
       "                                                  &#x27;region&#x27;),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;streams&#x27;, &#x27;duration_ms&#x27;,\n",
       "                                                   &#x27;af_danceability&#x27;,\n",
       "                                                   &#x27;af_energy&#x27;, &#x27;af_key&#x27;,\n",
       "                                                   &#x27;af_loudness&#x27;,\n",
       "                                                   &#x27;af_speechiness&#x27;,\n",
       "                                                   &#x27;af_acousticness&#x27;,\n",
       "                                                   &#x27;af_instrumentalness&#x27;,\n",
       "                                                   &#x27;af_liveness&#x27;, &#x27;af_valence&#x27;,\n",
       "                                                   &#x27;af_tempo&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                                   CountVectorizer(preprocessor=&lt;function preprocesar at 0x000001DA3AB40360&gt;)),\n",
       "                                                                  (&#x27;to_dense&#x27;,\n",
       "                                                                   FunctionTransformer(accept_sparse=True,\n",
       "                                                                                       func=&lt;function &lt;lambda&gt; at 0x000001DA1CA90040&gt;))]),\n",
       "                                                  &#x27;region&#x27;),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;streams&#x27;, &#x27;duration_ms&#x27;,\n",
       "                                                   &#x27;af_danceability&#x27;,\n",
       "                                                   &#x27;af_energy&#x27;, &#x27;af_key&#x27;,\n",
       "                                                   &#x27;af_loudness&#x27;,\n",
       "                                                   &#x27;af_speechiness&#x27;,\n",
       "                                                   &#x27;af_acousticness&#x27;,\n",
       "                                                   &#x27;af_instrumentalness&#x27;,\n",
       "                                                   &#x27;af_liveness&#x27;, &#x27;af_valence&#x27;,\n",
       "                                                   &#x27;af_tempo&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, RandomForestClassifier(random_state=42))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                  CountVectorizer(preprocessor=&lt;function preprocesar at 0x000001DA3AB40360&gt;)),\n",
       "                                                 (&#x27;to_dense&#x27;,\n",
       "                                                  FunctionTransformer(accept_sparse=True,\n",
       "                                                                      func=&lt;function &lt;lambda&gt; at 0x000001DA1CA90040&gt;))]),\n",
       "                                 &#x27;region&#x27;),\n",
       "                                (&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;streams&#x27;, &#x27;duration_ms&#x27;, &#x27;af_danceability&#x27;,\n",
       "                                  &#x27;af_energy&#x27;, &#x27;af_key&#x27;, &#x27;af_loudness&#x27;,\n",
       "                                  &#x27;af_speechiness&#x27;, &#x27;af_acousticness&#x27;,\n",
       "                                  &#x27;af_instrumentalness&#x27;, &#x27;af_liveness&#x27;,\n",
       "                                  &#x27;af_valence&#x27;, &#x27;af_tempo&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">text</label><div class=\"sk-toggleable__content fitted\"><pre>region</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(preprocessor=&lt;function preprocesar at 0x000001DA3AB40360&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(accept_sparse=True,\n",
       "                    func=&lt;function &lt;lambda&gt; at 0x000001DA1CA90040&gt;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">num</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;streams&#x27;, &#x27;duration_ms&#x27;, &#x27;af_danceability&#x27;, &#x27;af_energy&#x27;, &#x27;af_key&#x27;, &#x27;af_loudness&#x27;, &#x27;af_speechiness&#x27;, &#x27;af_acousticness&#x27;, &#x27;af_instrumentalness&#x27;, &#x27;af_liveness&#x27;, &#x27;af_valence&#x27;, &#x27;af_tempo&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('text',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   CountVectorizer(preprocessor=<function preprocesar at 0x000001DA3AB40360>)),\n",
       "                                                                  ('to_dense',\n",
       "                                                                   FunctionTransformer(accept_sparse=True,\n",
       "                                                                                       func=<function <lambda> at 0x000001DA1CA90040>))]),\n",
       "                                                  'region'),\n",
       "                                                 ('num', StandardScaler(),\n",
       "                                                  ['streams', 'duration_ms',\n",
       "                                                   'af_danceability',\n",
       "                                                   'af_energy', 'af_key',\n",
       "                                                   'af_loudness',\n",
       "                                                   'af_speechiness',\n",
       "                                                   'af_acousticness',\n",
       "                                                   'af_instrumentalness',\n",
       "                                                   'af_liveness', 'af_valence',\n",
       "                                                   'af_tempo'])])),\n",
       "                ('classifier', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predecimos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluamos la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.93      1.00      0.97       115\n",
      "         Low       0.77      0.74      0.75        54\n",
      " Medium-High       0.94      0.90      0.92        67\n",
      "  Medium-Low       0.75      0.72      0.74        64\n",
      "\n",
      "    accuracy                           0.87       300\n",
      "   macro avg       0.85      0.84      0.84       300\n",
      "weighted avg       0.87      0.87      0.87       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "target_names = ['High', 'Low', 'Medium-High', 'Medium-Low']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados: \n",
    "Podemos observar que se tiene buenos métricas para predecir que una canción tendrá una alta popularidad pero no tan buenas métricas para baja popularidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camino a seguir\n",
    "Probaremos reducir la cantidad de parámetros a utilizar y probar distintos modelos de clasificación, considerando todo el dataset y no solo una parte de él. \n",
    "\n",
    "### Replanteamiento de la pregunta\n",
    "\n",
    "¿Cuál será la popularidad de una canción en una región debido a sus atributos?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
