{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimento:\n",
    "Buscamos lograr contestar la pregunta:\n",
    "\n",
    "¿Es posible asociar el valor de alguna característica de la música como su energía o su tempo con un lugar geográfico?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#juntar paises en base al continente\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('C:/Users/diego/OneDrive/Escritorio/universidad/semestre10/mineria/T2/Insight_Alchemist/Spotify.xlsx')\n",
    "\n",
    "#Ajustamos columnas para contraarrestar error de formato en archivo xlsx\n",
    "df['duration_ms'] = df['duration_ms']/10\n",
    "df['popularity'] = df['popularity']/10\n",
    "df['streams'] = df['streams']/10\n",
    "df['af_danceability'] = df['af_danceability']/1000\n",
    "df['af_energy'] = df['af_energy']/1000\n",
    "df['af_key'] = df['af_key']/10\n",
    "df['af_loudness'] = df['af_loudness']/1000\n",
    "df['af_speechiness'] = df['af_speechiness']/1000\n",
    "df['af_acousticness'] = df['af_acousticness']/1000\n",
    "df['af_instrumentalness'] = df['af_instrumentalness']/1000\n",
    "df['af_liveness'] = df['af_liveness']/1000\n",
    "df['af_valence'] = df['af_valence']/1000\n",
    "df['af_tempo'] = df['af_tempo']/1000\n",
    "df['af_time_signature'] = df['af_time_signature']/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero modificamos la información de la columna regiones para reducir las clases al agrupar los países por regiones geográficas más amplia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = [\n",
    "    (['Morocco','South Africa'],'Africa'),\n",
    "    (['Argentina','Bolivia','Brazil','Chile','Colombia','Costa Rica','Dominican Republic','Ecuador','El Salvador','Guatemala','Honduras','Mexico','Nicaragua','Panama','Paraguay','Peru','Uruguay'],'America_latina'),\n",
    "    (['Canada','United States'],'America_norte'),\n",
    "    (['Hong Kong','India','Indonesia','Japan','Malaysia','Philippines','Singapore','Taiwan','Thailand','Vietnam'],'Asia'),\n",
    "    (['Andorra','Austria','Belgium','Bulgaria','Czech Republic','Denmark','Estonia','Finland','France','Germany','Greece','Hungary','Iceland','Ireland','Italy','Latvia','Lithuania','Luxembourg',\n",
    "     'Netherlands','Norway','Poland','Portugal','Romania','Russia','Slovakia','Spain','Sweden','Switzerland','Ukraine','United Kingdom'],'Europa'),\n",
    "    (['Australia','New Zealand'],'Oceania'),\n",
    "    (['Egypt','Israel','Saudi Arabia','Turkey','United Arab Emirates'],'Oriente_medio')\n",
    "]\n",
    "\n",
    "def apply_etiqueta(elemento):\n",
    "    for i in d1:\n",
    "        if elemento in i[0]:\n",
    "            return i[1]\n",
    "        \n",
    "new_reg = df[\"region\"]\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    new_data = apply_etiqueta(row[\"region\"])\n",
    "    new_reg.iat[index] = new_data\n",
    "\n",
    "#se reemplaza la columa de region\n",
    "df[\"region\"] = new_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para encontrar si esta relación existe vamos a usar un Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos atributo por atributo probando para ver cual tiene mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af_danceability\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.42      0.02      0.03      1785\n",
      "America_latina       0.53      0.50      0.52     15151\n",
      " America_norte       0.88      0.00      0.01      1785\n",
      "          Asia       0.52      0.26      0.35      8921\n",
      "        Europa       0.51      0.80      0.62     25448\n",
      "       Oceania       0.53      0.01      0.03      1785\n",
      " Oriente_medio       0.46      0.04      0.07      4462\n",
      "\n",
      "      accuracy                           0.51     59337\n",
      "     macro avg       0.55      0.23      0.23     59337\n",
      "  weighted avg       0.52      0.51      0.46     59337\n",
      "\n",
      "af_energy\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.56      0.02      0.03      1785\n",
      "America_latina       0.55      0.53      0.54     15151\n",
      " America_norte       0.31      0.01      0.02      1785\n",
      "          Asia       0.51      0.28      0.36      8921\n",
      "        Europa       0.52      0.80      0.63     25448\n",
      "       Oceania       0.45      0.02      0.05      1785\n",
      " Oriente_medio       0.51      0.03      0.06      4462\n",
      "\n",
      "      accuracy                           0.53     59337\n",
      "     macro avg       0.49      0.24      0.24     59337\n",
      "  weighted avg       0.52      0.53      0.47     59337\n",
      "\n",
      "af_key\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.00      0.00      0.00      1785\n",
      "America_latina       0.00      0.00      0.00     15151\n",
      " America_norte       0.00      0.00      0.00      1785\n",
      "          Asia       0.00      0.00      0.00      8921\n",
      "        Europa       0.43      1.00      0.60     25448\n",
      "       Oceania       0.00      0.00      0.00      1785\n",
      " Oriente_medio       0.00      0.00      0.00      4462\n",
      "\n",
      "      accuracy                           0.43     59337\n",
      "     macro avg       0.06      0.14      0.09     59337\n",
      "  weighted avg       0.18      0.43      0.26     59337\n",
      "\n",
      "af_loudness\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.79      0.39      0.52      1785\n",
      "America_latina       0.75      0.71      0.73     15151\n",
      " America_norte       0.55      0.12      0.20      1785\n",
      "          Asia       0.75      0.57      0.65      8921\n",
      "        Europa       0.64      0.88      0.74     25448\n",
      "       Oceania       0.67      0.18      0.28      1785\n",
      " Oriente_medio       0.71      0.28      0.41      4462\n",
      "\n",
      "      accuracy                           0.68     59337\n",
      "     macro avg       0.70      0.45      0.50     59337\n",
      "  weighted avg       0.69      0.68      0.66     59337\n",
      "\n",
      "af_mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.00      0.00      0.00      1785\n",
      "America_latina       0.00      0.00      0.00     15151\n",
      " America_norte       0.00      0.00      0.00      1785\n",
      "          Asia       0.00      0.00      0.00      8921\n",
      "        Europa       0.43      1.00      0.60     25448\n",
      "       Oceania       0.00      0.00      0.00      1785\n",
      " Oriente_medio       0.00      0.00      0.00      4462\n",
      "\n",
      "      accuracy                           0.43     59337\n",
      "     macro avg       0.06      0.14      0.09     59337\n",
      "  weighted avg       0.18      0.43      0.26     59337\n",
      "\n",
      "af_speechiness\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.50      0.07      0.13      1785\n",
      "America_latina       0.56      0.51      0.54     15151\n",
      " America_norte       0.24      0.00      0.00      1785\n",
      "          Asia       0.49      0.25      0.33      8921\n",
      "        Europa       0.52      0.82      0.64     25448\n",
      "       Oceania       0.63      0.02      0.04      1785\n",
      " Oriente_medio       0.42      0.03      0.05      4462\n",
      "\n",
      "      accuracy                           0.53     59337\n",
      "     macro avg       0.48      0.25      0.25     59337\n",
      "  weighted avg       0.51      0.53      0.47     59337\n",
      "\n",
      "af_acousticness\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.47      0.04      0.08      1785\n",
      "America_latina       0.56      0.51      0.53     15151\n",
      " America_norte       0.29      0.01      0.02      1785\n",
      "          Asia       0.53      0.27      0.36      8921\n",
      "        Europa       0.52      0.82      0.64     25448\n",
      "       Oceania       0.42      0.02      0.04      1785\n",
      " Oriente_medio       0.44      0.04      0.07      4462\n",
      "\n",
      "      accuracy                           0.53     59337\n",
      "     macro avg       0.46      0.24      0.25     59337\n",
      "  weighted avg       0.51      0.53      0.47     59337\n",
      "\n",
      "af_liveness\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.50      0.06      0.11      1785\n",
      "America_latina       0.54      0.47      0.50     15151\n",
      " America_norte       0.43      0.01      0.02      1785\n",
      "          Asia       0.44      0.18      0.26      8921\n",
      "        Europa       0.50      0.82      0.62     25448\n",
      "       Oceania       0.51      0.06      0.11      1785\n",
      " Oriente_medio       0.39      0.04      0.08      4462\n",
      "\n",
      "      accuracy                           0.51     59337\n",
      "     macro avg       0.47      0.24      0.24     59337\n",
      "  weighted avg       0.49      0.51      0.45     59337\n",
      "\n",
      "af_valence\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.38      0.04      0.07      1785\n",
      "America_latina       0.61      0.51      0.56     15151\n",
      " America_norte       0.43      0.01      0.01      1785\n",
      "          Asia       0.50      0.27      0.35      8921\n",
      "        Europa       0.52      0.84      0.64     25448\n",
      "       Oceania       0.48      0.01      0.02      1785\n",
      " Oriente_medio       0.34      0.02      0.05      4462\n",
      "\n",
      "      accuracy                           0.54     59337\n",
      "     macro avg       0.47      0.24      0.24     59337\n",
      "  weighted avg       0.52      0.54      0.48     59337\n",
      "\n",
      "af_tempo\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.85      0.40      0.54      1785\n",
      "America_latina       0.79      0.72      0.75     15151\n",
      " America_norte       0.65      0.16      0.25      1785\n",
      "          Asia       0.80      0.62      0.70      8921\n",
      "        Europa       0.66      0.90      0.76     25448\n",
      "       Oceania       0.78      0.21      0.33      1785\n",
      " Oriente_medio       0.77      0.33      0.46      4462\n",
      "\n",
      "      accuracy                           0.71     59337\n",
      "     macro avg       0.76      0.48      0.54     59337\n",
      "  weighted avg       0.73      0.71      0.69     59337\n",
      "\n",
      "af_time_signature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\diego\\OneDrive\\Escritorio\\universidad\\semestre10\\mineria\\T2\\Insight_Alchemist\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.00      0.00      0.00      1785\n",
      "America_latina       0.00      0.00      0.00     15151\n",
      " America_norte       0.00      0.00      0.00      1785\n",
      "          Asia       0.00      0.00      0.00      8921\n",
      "        Europa       0.43      1.00      0.60     25448\n",
      "       Oceania       0.00      0.00      0.00      1785\n",
      " Oriente_medio       0.00      0.00      0.00      4462\n",
      "\n",
      "      accuracy                           0.43     59337\n",
      "     macro avg       0.06      0.14      0.09     59337\n",
      "  weighted avg       0.18      0.43      0.26     59337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ['af_danceability','af_energy', 'af_key', 'af_loudness', 'af_mode', 'af_speechiness','af_acousticness', 'af_liveness', 'af_valence','af_tempo', 'af_time_signature']:\n",
    "\n",
    "    df = df.dropna(subset=[\"region\", i])  # Drop rows where target or feature is NaN\n",
    "    X = df[i].copy().values.reshape(-1, 1)\n",
    "    y = df[\"region\"]\n",
    "\n",
    "    #primero separamos los datos de entrenamiento y validacion/test\n",
    "    X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X,y,test_size=0.3,random_state=0,stratify=y)\n",
    "\n",
    "    # Luego separamos los datos de validación y pruebas                                       0.5 x 0.3 = 0.15\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=0, stratify=y_val_and_test)\n",
    "\n",
    "    #estandarizacion de datos, transformar los datos de manera que tengan media 0 y desviacion estandar 1.\n",
    "    std_scaler = StandardScaler()\n",
    "    X_train_std_scaled = std_scaler.fit_transform(X_train)\n",
    "\n",
    "    X_val_std_scaled = std_scaler.transform(X_val)\n",
    "    X_test_std_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "    #definimos nuestro modelo\n",
    "    clf = DecisionTreeClassifier(criterion=\"gini\",random_state=0)\n",
    "\n",
    "    #entrenamos al modelo con fit\n",
    "    clf.fit(X_train_std_scaled, y_train)   ## Entrenar usando X (features), y (clase)\n",
    "\n",
    "    #realizamos predicciones de nuestros datos con los datos de validación\n",
    "    y_val_pred = clf.predict(X_val_std_scaled)\n",
    "\n",
    "\n",
    "    #metricas de las predicciones\n",
    "    print(i)\n",
    "    print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De lo anterior se pude observar que las dos características que presentan mayor relación son loudness y tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probamos con todas las características a la vez para ver si se encuentra un mejor resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"region\", i])  # Drop rows where target or feature is NaN\n",
    "X = df[['af_danceability','af_energy', 'af_key', 'af_loudness', 'af_mode', 'af_speechiness','af_acousticness', 'af_liveness', 'af_valence','af_tempo', 'af_time_signature']].copy()\n",
    "y = df[\"region\"]\n",
    "\n",
    "#primero separamos los datos de entrenamiento y validacion/test\n",
    "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X,y,test_size=0.3,random_state=0,stratify=y)\n",
    "\n",
    "# Luego separamos los datos de validación y pruebas                                       0.5 x 0.3 = 0.15\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=0, stratify=y_val_and_test)\n",
    "\n",
    "#estandarizacion de datos, transformar los datos de manera que tengan media 0 y desviacion estandar 1.\n",
    "std_scaler = StandardScaler()\n",
    "X_train_std_scaled = std_scaler.fit_transform(X_train)\n",
    "\n",
    "X_val_std_scaled = std_scaler.transform(X_val)\n",
    "X_test_std_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "#definimos nuestro modelo\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\",random_state=0)\n",
    "\n",
    "#entrenamos al modelo con fit\n",
    "clf.fit(X_train_std_scaled, y_train)   ## Entrenar usando X (features), y (clase)\n",
    "\n",
    "#realizamos predicciones de nuestros datos con los datos de validación\n",
    "y_val_pred = clf.predict(X_val_std_scaled)\n",
    "\n",
    "\n",
    "#metricas de las predicciones\n",
    "print(\"todas\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es mejor que cualquiera de los intentos individuales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se hará con los dos mejores resultados anteriores a la vez por si al agregar todos los dados se está perdiendo algo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af_loudness y af_tempo\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.94      0.48      0.64      1785\n",
      "America_latina       0.82      0.75      0.78     15151\n",
      " America_norte       0.64      0.19      0.29      1785\n",
      "          Asia       0.87      0.68      0.76      8921\n",
      "        Europa       0.68      0.92      0.78     25448\n",
      "       Oceania       0.83      0.25      0.39      1785\n",
      " Oriente_medio       0.86      0.38      0.52      4462\n",
      "\n",
      "      accuracy                           0.75     59337\n",
      "     macro avg       0.81      0.52      0.59     59337\n",
      "  weighted avg       0.77      0.75      0.73     59337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"region\", i])  # Drop rows where target or feature is NaN\n",
    "X = df[[\"af_loudness\",\"af_tempo\"]].copy()\n",
    "y = df[\"region\"]\n",
    "\n",
    "#primero separamos los datos de entrenamiento y validacion/test\n",
    "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X,y,test_size=0.3,random_state=0,stratify=y)\n",
    "\n",
    "# Luego separamos los datos de validación y pruebas                                       0.5 x 0.3 = 0.15\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=0, stratify=y_val_and_test)\n",
    "\n",
    "#estandarizacion de datos, transformar los datos de manera que tengan media 0 y desviacion estandar 1.\n",
    "std_scaler = StandardScaler()\n",
    "X_train_std_scaled = std_scaler.fit_transform(X_train)\n",
    "\n",
    "X_val_std_scaled = std_scaler.transform(X_val)\n",
    "X_test_std_scaled = std_scaler.transform(X_test)\n",
    "\n",
    "#definimos nuestro modelo\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\",random_state=0)\n",
    "\n",
    "#entrenamos al modelo con fit\n",
    "clf.fit(X_train_std_scaled, y_train)   ## Entrenar usando X (features), y (clase)\n",
    "\n",
    "#realizamos predicciones de nuestros datos con los datos de validación\n",
    "y_val_pred = clf.predict(X_val_std_scaled)\n",
    "\n",
    "\n",
    "#metricas de las predicciones\n",
    "print(\"af_loudness y af_tempo\")\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La con mejor resultado sigue siendo loudness y key, al parecer al agregar el resto de los datos no suma ni resta al resultado por lo tanto tomares el de los dos mejores para el test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todas\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        Africa       0.94      0.46      0.62      1785\n",
      "America_latina       0.82      0.75      0.78     15151\n",
      " America_norte       0.64      0.17      0.27      1785\n",
      "          Asia       0.88      0.67      0.76      8922\n",
      "        Europa       0.68      0.92      0.78     25448\n",
      "       Oceania       0.83      0.22      0.35      1785\n",
      " Oriente_medio       0.87      0.38      0.53      4461\n",
      "\n",
      "      accuracy                           0.74     59337\n",
      "     macro avg       0.81      0.51      0.59     59337\n",
      "  weighted avg       0.77      0.74      0.73     59337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#realizamos predicciones de nuestros datos con los datos de validación\n",
    "y_test_pred = clf.predict(X_test_std_scaled)\n",
    "\n",
    "\n",
    "#metricas de las predicciones\n",
    "print(\"todas\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se podría seguir experimentando al buscar alguna otra combinación de características que den un mejor resultado, pero tomar demasiado tiempo al ser demasiado combinaciones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
